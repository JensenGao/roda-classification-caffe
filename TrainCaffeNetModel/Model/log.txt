I0716 18:17:33.120163  5440 caffe.cpp:211] Use CPU.
I0716 18:17:34.709813  5440 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0716 18:17:34.709813  5440 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 10
base_lr: 0.01
display: 20
max_iter: 1000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 2000
snapshot_prefix: "E:/1/TrainModel/Model/"
solver_mode: CPU
net: "E:/1/TrainModel/Model/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0716 18:17:34.710825  5440 solver.cpp:91] Creating training net from net file: E:/1/TrainModel/Model/train_val.prototxt
I0716 18:17:34.711819  5440 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0716 18:17:34.711819  5440 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0716 18:17:34.711819  5440 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_file: "E:/1/TrainModel/imagenet_mean.binaryproto"
  }
  data_param {
    source: "E:/1/TrainModel/train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0716 18:17:34.713325  5440 layer_factory.hpp:77] Creating layer data
I0716 18:17:34.715829  5440 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0716 18:17:34.715829  5440 net.cpp:100] Creating Layer data
I0716 18:17:34.715829  5440 net.cpp:418] data -> data
I0716 18:17:34.715829  5440 net.cpp:418] data -> label
I0716 18:17:34.715829  5440 data_transformer.cpp:25] Loading mean file from: E:/1/TrainModel/imagenet_mean.binaryproto
I0716 18:17:34.715829 10768 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0716 18:17:34.715829 10768 db_lmdb.cpp:40] Opened lmdb E:/1/TrainModel/train_lmdb
I0716 18:17:34.715829  5440 data_layer.cpp:41] output data size: 100,3,100,100
I0716 18:17:34.731459  5440 net.cpp:150] Setting up data
I0716 18:17:34.731459  5440 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0716 18:17:34.731459  5440 net.cpp:157] Top shape: 100 (100)
I0716 18:17:34.731459  5440 net.cpp:165] Memory required for data: 12000400
I0716 18:17:34.731459  5440 layer_factory.hpp:77] Creating layer conv1
I0716 18:17:34.731459  5440 net.cpp:100] Creating Layer conv1
I0716 18:17:34.731459  5440 net.cpp:444] conv1 <- data
I0716 18:17:34.731459  5440 net.cpp:418] conv1 -> conv1
I0716 18:17:34.731459  7828 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0716 18:17:35.295397  5440 net.cpp:150] Setting up conv1
I0716 18:17:35.295397  5440 net.cpp:157] Top shape: 100 96 23 23 (5078400)
I0716 18:17:35.295397  5440 net.cpp:165] Memory required for data: 32314000
I0716 18:17:35.295397  5440 layer_factory.hpp:77] Creating layer relu1
I0716 18:17:35.295397  5440 net.cpp:100] Creating Layer relu1
I0716 18:17:35.295397  5440 net.cpp:444] relu1 <- conv1
I0716 18:17:35.295397  5440 net.cpp:405] relu1 -> conv1 (in-place)
I0716 18:17:35.295397  5440 net.cpp:150] Setting up relu1
I0716 18:17:35.295397  5440 net.cpp:157] Top shape: 100 96 23 23 (5078400)
I0716 18:17:35.295397  5440 net.cpp:165] Memory required for data: 52627600
I0716 18:17:35.295397  5440 layer_factory.hpp:77] Creating layer pool1
I0716 18:17:35.295397  5440 net.cpp:100] Creating Layer pool1
I0716 18:17:35.295397  5440 net.cpp:444] pool1 <- conv1
I0716 18:17:35.295397  5440 net.cpp:418] pool1 -> pool1
I0716 18:17:35.295397  5440 net.cpp:150] Setting up pool1
I0716 18:17:35.295397  5440 net.cpp:157] Top shape: 100 96 11 11 (1161600)
I0716 18:17:35.295397  5440 net.cpp:165] Memory required for data: 57274000
I0716 18:17:35.295397  5440 layer_factory.hpp:77] Creating layer norm1
I0716 18:17:35.295397  5440 net.cpp:100] Creating Layer norm1
I0716 18:17:35.295397  5440 net.cpp:444] norm1 <- pool1
I0716 18:17:35.295397  5440 net.cpp:418] norm1 -> norm1
I0716 18:17:35.295397  5440 net.cpp:150] Setting up norm1
I0716 18:17:35.295397  5440 net.cpp:157] Top shape: 100 96 11 11 (1161600)
I0716 18:17:35.295397  5440 net.cpp:165] Memory required for data: 61920400
I0716 18:17:35.295397  5440 layer_factory.hpp:77] Creating layer conv2
I0716 18:17:35.295397  5440 net.cpp:100] Creating Layer conv2
I0716 18:17:35.295397  5440 net.cpp:444] conv2 <- norm1
I0716 18:17:35.295397  5440 net.cpp:418] conv2 -> conv2
I0716 18:17:35.315037  5440 net.cpp:150] Setting up conv2
I0716 18:17:35.315037  5440 net.cpp:157] Top shape: 100 256 11 11 (3097600)
I0716 18:17:35.315037  5440 net.cpp:165] Memory required for data: 74310800
I0716 18:17:35.315538  5440 layer_factory.hpp:77] Creating layer relu2
I0716 18:17:35.315538  5440 net.cpp:100] Creating Layer relu2
I0716 18:17:35.315538  5440 net.cpp:444] relu2 <- conv2
I0716 18:17:35.315538  5440 net.cpp:405] relu2 -> conv2 (in-place)
I0716 18:17:35.315538  5440 net.cpp:150] Setting up relu2
I0716 18:17:35.315538  5440 net.cpp:157] Top shape: 100 256 11 11 (3097600)
I0716 18:17:35.315538  5440 net.cpp:165] Memory required for data: 86701200
I0716 18:17:35.315538  5440 layer_factory.hpp:77] Creating layer pool2
I0716 18:17:35.315538  5440 net.cpp:100] Creating Layer pool2
I0716 18:17:35.315538  5440 net.cpp:444] pool2 <- conv2
I0716 18:17:35.315538  5440 net.cpp:418] pool2 -> pool2
I0716 18:17:35.315538  5440 net.cpp:150] Setting up pool2
I0716 18:17:35.315538  5440 net.cpp:157] Top shape: 100 256 5 5 (640000)
I0716 18:17:35.315538  5440 net.cpp:165] Memory required for data: 89261200
I0716 18:17:35.315538  5440 layer_factory.hpp:77] Creating layer norm2
I0716 18:17:35.315538  5440 net.cpp:100] Creating Layer norm2
I0716 18:17:35.315538  5440 net.cpp:444] norm2 <- pool2
I0716 18:17:35.315538  5440 net.cpp:418] norm2 -> norm2
I0716 18:17:35.316040  5440 net.cpp:150] Setting up norm2
I0716 18:17:35.316040  5440 net.cpp:157] Top shape: 100 256 5 5 (640000)
I0716 18:17:35.316040  5440 net.cpp:165] Memory required for data: 91821200
I0716 18:17:35.316040  5440 layer_factory.hpp:77] Creating layer conv3
I0716 18:17:35.316040  5440 net.cpp:100] Creating Layer conv3
I0716 18:17:35.316040  5440 net.cpp:444] conv3 <- norm2
I0716 18:17:35.316040  5440 net.cpp:418] conv3 -> conv3
I0716 18:17:35.317543  5440 net.cpp:150] Setting up conv3
I0716 18:17:35.317543  5440 net.cpp:157] Top shape: 100 384 5 5 (960000)
I0716 18:17:35.317543  5440 net.cpp:165] Memory required for data: 95661200
I0716 18:17:35.317543  5440 layer_factory.hpp:77] Creating layer relu3
I0716 18:17:35.317543  5440 net.cpp:100] Creating Layer relu3
I0716 18:17:35.317543  5440 net.cpp:444] relu3 <- conv3
I0716 18:17:35.317543  5440 net.cpp:405] relu3 -> conv3 (in-place)
I0716 18:17:35.317543  5440 net.cpp:150] Setting up relu3
I0716 18:17:35.317543  5440 net.cpp:157] Top shape: 100 384 5 5 (960000)
I0716 18:17:35.317543  5440 net.cpp:165] Memory required for data: 99501200
I0716 18:17:35.317543  5440 layer_factory.hpp:77] Creating layer conv4
I0716 18:17:35.317543  5440 net.cpp:100] Creating Layer conv4
I0716 18:17:35.317543  5440 net.cpp:444] conv4 <- conv3
I0716 18:17:35.317543  5440 net.cpp:418] conv4 -> conv4
I0716 18:17:35.333184  5440 net.cpp:150] Setting up conv4
I0716 18:17:35.333184  5440 net.cpp:157] Top shape: 100 384 5 5 (960000)
I0716 18:17:35.333184  5440 net.cpp:165] Memory required for data: 103341200
I0716 18:17:35.333184  5440 layer_factory.hpp:77] Creating layer relu4
I0716 18:17:35.333184  5440 net.cpp:100] Creating Layer relu4
I0716 18:17:35.333184  5440 net.cpp:444] relu4 <- conv4
I0716 18:17:35.333184  5440 net.cpp:405] relu4 -> conv4 (in-place)
I0716 18:17:35.333184  5440 net.cpp:150] Setting up relu4
I0716 18:17:35.333184  5440 net.cpp:157] Top shape: 100 384 5 5 (960000)
I0716 18:17:35.333184  5440 net.cpp:165] Memory required for data: 107181200
I0716 18:17:35.333184  5440 layer_factory.hpp:77] Creating layer conv5
I0716 18:17:35.333184  5440 net.cpp:100] Creating Layer conv5
I0716 18:17:35.333184  5440 net.cpp:444] conv5 <- conv4
I0716 18:17:35.333184  5440 net.cpp:418] conv5 -> conv5
I0716 18:17:35.333184  5440 net.cpp:150] Setting up conv5
I0716 18:17:35.333184  5440 net.cpp:157] Top shape: 100 256 5 5 (640000)
I0716 18:17:35.333184  5440 net.cpp:165] Memory required for data: 109741200
I0716 18:17:35.333184  5440 layer_factory.hpp:77] Creating layer relu5
I0716 18:17:35.333184  5440 net.cpp:100] Creating Layer relu5
I0716 18:17:35.333184  5440 net.cpp:444] relu5 <- conv5
I0716 18:17:35.333184  5440 net.cpp:405] relu5 -> conv5 (in-place)
I0716 18:17:35.333184  5440 net.cpp:150] Setting up relu5
I0716 18:17:35.333184  5440 net.cpp:157] Top shape: 100 256 5 5 (640000)
I0716 18:17:35.333184  5440 net.cpp:165] Memory required for data: 112301200
I0716 18:17:35.333184  5440 layer_factory.hpp:77] Creating layer pool5
I0716 18:17:35.333184  5440 net.cpp:100] Creating Layer pool5
I0716 18:17:35.333184  5440 net.cpp:444] pool5 <- conv5
I0716 18:17:35.333184  5440 net.cpp:418] pool5 -> pool5
I0716 18:17:35.333184  5440 net.cpp:150] Setting up pool5
I0716 18:17:35.333184  5440 net.cpp:157] Top shape: 100 256 2 2 (102400)
I0716 18:17:35.333184  5440 net.cpp:165] Memory required for data: 112710800
I0716 18:17:35.333184  5440 layer_factory.hpp:77] Creating layer fc6
I0716 18:17:35.333184  5440 net.cpp:100] Creating Layer fc6
I0716 18:17:35.333184  5440 net.cpp:444] fc6 <- pool5
I0716 18:17:35.333184  5440 net.cpp:418] fc6 -> fc6
I0716 18:17:35.380051  5440 net.cpp:150] Setting up fc6
I0716 18:17:35.380051  5440 net.cpp:157] Top shape: 100 4096 (409600)
I0716 18:17:35.380051  5440 net.cpp:165] Memory required for data: 114349200
I0716 18:17:35.380051  5440 layer_factory.hpp:77] Creating layer relu6
I0716 18:17:35.380051  5440 net.cpp:100] Creating Layer relu6
I0716 18:17:35.380051  5440 net.cpp:444] relu6 <- fc6
I0716 18:17:35.380051  5440 net.cpp:405] relu6 -> fc6 (in-place)
I0716 18:17:35.380051  5440 net.cpp:150] Setting up relu6
I0716 18:17:35.380051  5440 net.cpp:157] Top shape: 100 4096 (409600)
I0716 18:17:35.380051  5440 net.cpp:165] Memory required for data: 115987600
I0716 18:17:35.380051  5440 layer_factory.hpp:77] Creating layer drop6
I0716 18:17:35.380051  5440 net.cpp:100] Creating Layer drop6
I0716 18:17:35.380051  5440 net.cpp:444] drop6 <- fc6
I0716 18:17:35.380051  5440 net.cpp:405] drop6 -> fc6 (in-place)
I0716 18:17:35.380051  5440 net.cpp:150] Setting up drop6
I0716 18:17:35.380051  5440 net.cpp:157] Top shape: 100 4096 (409600)
I0716 18:17:35.380051  5440 net.cpp:165] Memory required for data: 117626000
I0716 18:17:35.380051  5440 layer_factory.hpp:77] Creating layer fc7
I0716 18:17:35.380051  5440 net.cpp:100] Creating Layer fc7
I0716 18:17:35.380051  5440 net.cpp:444] fc7 <- fc6
I0716 18:17:35.380051  5440 net.cpp:418] fc7 -> fc7
I0716 18:17:35.545181  5440 net.cpp:150] Setting up fc7
I0716 18:17:35.545181  5440 net.cpp:157] Top shape: 100 4096 (409600)
I0716 18:17:35.545181  5440 net.cpp:165] Memory required for data: 119264400
I0716 18:17:35.545181  5440 layer_factory.hpp:77] Creating layer relu7
I0716 18:17:35.545181  5440 net.cpp:100] Creating Layer relu7
I0716 18:17:35.545181  5440 net.cpp:444] relu7 <- fc7
I0716 18:17:35.545181  5440 net.cpp:405] relu7 -> fc7 (in-place)
I0716 18:17:35.546195  5440 net.cpp:150] Setting up relu7
I0716 18:17:35.546195  5440 net.cpp:157] Top shape: 100 4096 (409600)
I0716 18:17:35.546195  5440 net.cpp:165] Memory required for data: 120902800
I0716 18:17:35.546195  5440 layer_factory.hpp:77] Creating layer drop7
I0716 18:17:35.546195  5440 net.cpp:100] Creating Layer drop7
I0716 18:17:35.546195  5440 net.cpp:444] drop7 <- fc7
I0716 18:17:35.546195  5440 net.cpp:405] drop7 -> fc7 (in-place)
I0716 18:17:35.546723  5440 net.cpp:150] Setting up drop7
I0716 18:17:35.546723  5440 net.cpp:157] Top shape: 100 4096 (409600)
I0716 18:17:35.546723  5440 net.cpp:165] Memory required for data: 122541200
I0716 18:17:35.546723  5440 layer_factory.hpp:77] Creating layer fc8
I0716 18:17:35.546723  5440 net.cpp:100] Creating Layer fc8
I0716 18:17:35.546723  5440 net.cpp:444] fc8 <- fc7
I0716 18:17:35.546723  5440 net.cpp:418] fc8 -> fc8
I0716 18:17:35.546723  5440 net.cpp:150] Setting up fc8
I0716 18:17:35.546723  5440 net.cpp:157] Top shape: 100 2 (200)
I0716 18:17:35.546723  5440 net.cpp:165] Memory required for data: 122542000
I0716 18:17:35.546723  5440 layer_factory.hpp:77] Creating layer loss
I0716 18:17:35.546723  5440 net.cpp:100] Creating Layer loss
I0716 18:17:35.546723  5440 net.cpp:444] loss <- fc8
I0716 18:17:35.546723  5440 net.cpp:444] loss <- label
I0716 18:17:35.546723  5440 net.cpp:418] loss -> loss
I0716 18:17:35.546723  5440 layer_factory.hpp:77] Creating layer loss
I0716 18:17:35.547188  5440 net.cpp:150] Setting up loss
I0716 18:17:35.547188  5440 net.cpp:157] Top shape: (1)
I0716 18:17:35.547188  5440 net.cpp:160]     with loss weight 1
I0716 18:17:35.547188  5440 net.cpp:165] Memory required for data: 122542004
I0716 18:17:35.547188  5440 net.cpp:226] loss needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] fc8 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] drop7 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu7 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] fc7 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] drop6 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu6 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] fc6 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] pool5 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu5 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] conv5 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu4 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] conv4 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu3 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] conv3 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] norm2 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] pool2 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu2 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] conv2 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] norm1 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] pool1 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] relu1 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:226] conv1 needs backward computation.
I0716 18:17:35.547188  5440 net.cpp:228] data does not need backward computation.
I0716 18:17:35.547188  5440 net.cpp:270] This network produces output loss
I0716 18:17:35.547188  5440 net.cpp:283] Network initialization done.
I0716 18:17:35.547722  5440 solver.cpp:181] Creating test net (#0) specified by net file: E:/1/TrainModel/Model/train_val.prototxt
I0716 18:17:35.547722  5440 net.cpp:332] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0716 18:17:35.547722  5440 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_file: "E:/1/TrainModel/imagenet_mean.binaryproto"
  }
  data_param {
    source: "E:/1/TrainModel/val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0716 18:17:35.548224  5440 layer_factory.hpp:77] Creating layer data
I0716 18:17:35.548224  5440 net.cpp:100] Creating Layer data
I0716 18:17:35.548224  5440 net.cpp:418] data -> data
I0716 18:17:35.548224  5440 net.cpp:418] data -> label
I0716 18:17:35.548224  5440 data_transformer.cpp:25] Loading mean file from: E:/1/TrainModel/imagenet_mean.binaryproto
I0716 18:17:35.550695   504 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0716 18:17:35.551213   504 db_lmdb.cpp:40] Opened lmdb E:/1/TrainModel/val_lmdb
I0716 18:17:35.551698  5440 data_layer.cpp:41] output data size: 50,3,100,100
I0716 18:17:35.558215  5440 net.cpp:150] Setting up data
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 3 100 100 (1500000)
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 (50)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 6000200
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer label_data_1_split
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer label_data_1_split
I0716 18:17:35.558215  5440 net.cpp:444] label_data_1_split <- label
I0716 18:17:35.558215  5440 net.cpp:418] label_data_1_split -> label_data_1_split_0
I0716 18:17:35.558215  5440 net.cpp:418] label_data_1_split -> label_data_1_split_1
I0716 18:17:35.558215  5440 net.cpp:150] Setting up label_data_1_split
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 (50)
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 (50)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 6000600
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer conv1
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer conv1
I0716 18:17:35.558215  5440 net.cpp:444] conv1 <- data
I0716 18:17:35.558215  5440 net.cpp:418] conv1 -> conv1
I0716 18:17:35.558215  5440 net.cpp:150] Setting up conv1
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 96 23 23 (2539200)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 16157400
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer relu1
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer relu1
I0716 18:17:35.558215  5440 net.cpp:444] relu1 <- conv1
I0716 18:17:35.558215  5440 net.cpp:405] relu1 -> conv1 (in-place)
I0716 18:17:35.558215  5440 net.cpp:150] Setting up relu1
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 96 23 23 (2539200)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 26314200
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer pool1
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer pool1
I0716 18:17:35.558215  5440 net.cpp:444] pool1 <- conv1
I0716 18:17:35.558215  5440 net.cpp:418] pool1 -> pool1
I0716 18:17:35.558215  5440 net.cpp:150] Setting up pool1
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 96 11 11 (580800)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 28637400
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer norm1
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer norm1
I0716 18:17:35.558215  5440 net.cpp:444] norm1 <- pool1
I0716 18:17:35.558215  5440 net.cpp:418] norm1 -> norm1
I0716 18:17:35.558215  5440 net.cpp:150] Setting up norm1
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 96 11 11 (580800)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 30960600
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer conv2
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer conv2
I0716 18:17:35.558215  5440 net.cpp:444] conv2 <- norm1
I0716 18:17:35.558215  5440 net.cpp:418] conv2 -> conv2
I0716 18:17:35.558215  9680 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0716 18:17:35.558215  5440 net.cpp:150] Setting up conv2
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 256 11 11 (1548800)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 37155800
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer relu2
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer relu2
I0716 18:17:35.558215  5440 net.cpp:444] relu2 <- conv2
I0716 18:17:35.558215  5440 net.cpp:405] relu2 -> conv2 (in-place)
I0716 18:17:35.558215  5440 net.cpp:150] Setting up relu2
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 256 11 11 (1548800)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 43351000
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer pool2
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer pool2
I0716 18:17:35.558215  5440 net.cpp:444] pool2 <- conv2
I0716 18:17:35.558215  5440 net.cpp:418] pool2 -> pool2
I0716 18:17:35.558215  5440 net.cpp:150] Setting up pool2
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 256 5 5 (320000)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 44631000
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer norm2
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer norm2
I0716 18:17:35.558215  5440 net.cpp:444] norm2 <- pool2
I0716 18:17:35.558215  5440 net.cpp:418] norm2 -> norm2
I0716 18:17:35.558215  5440 net.cpp:150] Setting up norm2
I0716 18:17:35.558215  5440 net.cpp:157] Top shape: 50 256 5 5 (320000)
I0716 18:17:35.558215  5440 net.cpp:165] Memory required for data: 45911000
I0716 18:17:35.558215  5440 layer_factory.hpp:77] Creating layer conv3
I0716 18:17:35.558215  5440 net.cpp:100] Creating Layer conv3
I0716 18:17:35.558215  5440 net.cpp:444] conv3 <- norm2
I0716 18:17:35.558215  5440 net.cpp:418] conv3 -> conv3
I0716 18:17:35.573848  5440 net.cpp:150] Setting up conv3
I0716 18:17:35.573848  5440 net.cpp:157] Top shape: 50 384 5 5 (480000)
I0716 18:17:35.573848  5440 net.cpp:165] Memory required for data: 47831000
I0716 18:17:35.573848  5440 layer_factory.hpp:77] Creating layer relu3
I0716 18:17:35.573848  5440 net.cpp:100] Creating Layer relu3
I0716 18:17:35.573848  5440 net.cpp:444] relu3 <- conv3
I0716 18:17:35.573848  5440 net.cpp:405] relu3 -> conv3 (in-place)
I0716 18:17:35.573848  5440 net.cpp:150] Setting up relu3
I0716 18:17:35.573848  5440 net.cpp:157] Top shape: 50 384 5 5 (480000)
I0716 18:17:35.573848  5440 net.cpp:165] Memory required for data: 49751000
I0716 18:17:35.573848  5440 layer_factory.hpp:77] Creating layer conv4
I0716 18:17:35.573848  5440 net.cpp:100] Creating Layer conv4
I0716 18:17:35.573848  5440 net.cpp:444] conv4 <- conv3
I0716 18:17:35.573848  5440 net.cpp:418] conv4 -> conv4
I0716 18:17:35.589484  5440 net.cpp:150] Setting up conv4
I0716 18:17:35.589484  5440 net.cpp:157] Top shape: 50 384 5 5 (480000)
I0716 18:17:35.589484  5440 net.cpp:165] Memory required for data: 51671000
I0716 18:17:35.589484  5440 layer_factory.hpp:77] Creating layer relu4
I0716 18:17:35.589484  5440 net.cpp:100] Creating Layer relu4
I0716 18:17:35.589484  5440 net.cpp:444] relu4 <- conv4
I0716 18:17:35.589484  5440 net.cpp:405] relu4 -> conv4 (in-place)
I0716 18:17:35.589484  5440 net.cpp:150] Setting up relu4
I0716 18:17:35.589484  5440 net.cpp:157] Top shape: 50 384 5 5 (480000)
I0716 18:17:35.589484  5440 net.cpp:165] Memory required for data: 53591000
I0716 18:17:35.589484  5440 layer_factory.hpp:77] Creating layer conv5
I0716 18:17:35.589484  5440 net.cpp:100] Creating Layer conv5
I0716 18:17:35.589484  5440 net.cpp:444] conv5 <- conv4
I0716 18:17:35.589484  5440 net.cpp:418] conv5 -> conv5
I0716 18:17:35.589484  5440 net.cpp:150] Setting up conv5
I0716 18:17:35.589484  5440 net.cpp:157] Top shape: 50 256 5 5 (320000)
I0716 18:17:35.589484  5440 net.cpp:165] Memory required for data: 54871000
I0716 18:17:35.589484  5440 layer_factory.hpp:77] Creating layer relu5
I0716 18:17:35.589484  5440 net.cpp:100] Creating Layer relu5
I0716 18:17:35.589484  5440 net.cpp:444] relu5 <- conv5
I0716 18:17:35.589484  5440 net.cpp:405] relu5 -> conv5 (in-place)
I0716 18:17:35.589484  5440 net.cpp:150] Setting up relu5
I0716 18:17:35.589484  5440 net.cpp:157] Top shape: 50 256 5 5 (320000)
I0716 18:17:35.589484  5440 net.cpp:165] Memory required for data: 56151000
I0716 18:17:35.589484  5440 layer_factory.hpp:77] Creating layer pool5
I0716 18:17:35.589484  5440 net.cpp:100] Creating Layer pool5
I0716 18:17:35.589484  5440 net.cpp:444] pool5 <- conv5
I0716 18:17:35.589484  5440 net.cpp:418] pool5 -> pool5
I0716 18:17:35.589484  5440 net.cpp:150] Setting up pool5
I0716 18:17:35.589484  5440 net.cpp:157] Top shape: 50 256 2 2 (51200)
I0716 18:17:35.589484  5440 net.cpp:165] Memory required for data: 56355800
I0716 18:17:35.589484  5440 layer_factory.hpp:77] Creating layer fc6
I0716 18:17:35.589484  5440 net.cpp:100] Creating Layer fc6
I0716 18:17:35.589484  5440 net.cpp:444] fc6 <- pool5
I0716 18:17:35.589484  5440 net.cpp:418] fc6 -> fc6
I0716 18:17:35.636385  5440 net.cpp:150] Setting up fc6
I0716 18:17:35.636385  5440 net.cpp:157] Top shape: 50 4096 (204800)
I0716 18:17:35.636385  5440 net.cpp:165] Memory required for data: 57175000
I0716 18:17:35.636385  5440 layer_factory.hpp:77] Creating layer relu6
I0716 18:17:35.636385  5440 net.cpp:100] Creating Layer relu6
I0716 18:17:35.636385  5440 net.cpp:444] relu6 <- fc6
I0716 18:17:35.636385  5440 net.cpp:405] relu6 -> fc6 (in-place)
I0716 18:17:35.636385  5440 net.cpp:150] Setting up relu6
I0716 18:17:35.636385  5440 net.cpp:157] Top shape: 50 4096 (204800)
I0716 18:17:35.636385  5440 net.cpp:165] Memory required for data: 57994200
I0716 18:17:35.636385  5440 layer_factory.hpp:77] Creating layer drop6
I0716 18:17:35.636385  5440 net.cpp:100] Creating Layer drop6
I0716 18:17:35.636385  5440 net.cpp:444] drop6 <- fc6
I0716 18:17:35.636385  5440 net.cpp:405] drop6 -> fc6 (in-place)
I0716 18:17:35.636385  5440 net.cpp:150] Setting up drop6
I0716 18:17:35.636385  5440 net.cpp:157] Top shape: 50 4096 (204800)
I0716 18:17:35.636385  5440 net.cpp:165] Memory required for data: 58813400
I0716 18:17:35.636385  5440 layer_factory.hpp:77] Creating layer fc7
I0716 18:17:35.636385  5440 net.cpp:100] Creating Layer fc7
I0716 18:17:35.636385  5440 net.cpp:444] fc7 <- fc6
I0716 18:17:35.636385  5440 net.cpp:418] fc7 -> fc7
I0716 18:17:35.858634  5440 net.cpp:150] Setting up fc7
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: 50 4096 (204800)
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 59632600
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer relu7
I0716 18:17:35.858634  5440 net.cpp:100] Creating Layer relu7
I0716 18:17:35.858634  5440 net.cpp:444] relu7 <- fc7
I0716 18:17:35.858634  5440 net.cpp:405] relu7 -> fc7 (in-place)
I0716 18:17:35.858634  5440 net.cpp:150] Setting up relu7
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: 50 4096 (204800)
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 60451800
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer drop7
I0716 18:17:35.858634  5440 net.cpp:100] Creating Layer drop7
I0716 18:17:35.858634  5440 net.cpp:444] drop7 <- fc7
I0716 18:17:35.858634  5440 net.cpp:405] drop7 -> fc7 (in-place)
I0716 18:17:35.858634  5440 net.cpp:150] Setting up drop7
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: 50 4096 (204800)
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 61271000
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer fc8
I0716 18:17:35.858634  5440 net.cpp:100] Creating Layer fc8
I0716 18:17:35.858634  5440 net.cpp:444] fc8 <- fc7
I0716 18:17:35.858634  5440 net.cpp:418] fc8 -> fc8
I0716 18:17:35.858634  5440 net.cpp:150] Setting up fc8
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: 50 2 (100)
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 61271400
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0716 18:17:35.858634  5440 net.cpp:100] Creating Layer fc8_fc8_0_split
I0716 18:17:35.858634  5440 net.cpp:444] fc8_fc8_0_split <- fc8
I0716 18:17:35.858634  5440 net.cpp:418] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0716 18:17:35.858634  5440 net.cpp:418] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0716 18:17:35.858634  5440 net.cpp:150] Setting up fc8_fc8_0_split
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: 50 2 (100)
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: 50 2 (100)
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 61272200
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer accuracy
I0716 18:17:35.858634  5440 net.cpp:100] Creating Layer accuracy
I0716 18:17:35.858634  5440 net.cpp:444] accuracy <- fc8_fc8_0_split_0
I0716 18:17:35.858634  5440 net.cpp:444] accuracy <- label_data_1_split_0
I0716 18:17:35.858634  5440 net.cpp:418] accuracy -> accuracy
I0716 18:17:35.858634  5440 net.cpp:150] Setting up accuracy
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: (1)
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 61272204
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer loss
I0716 18:17:35.858634  5440 net.cpp:100] Creating Layer loss
I0716 18:17:35.858634  5440 net.cpp:444] loss <- fc8_fc8_0_split_1
I0716 18:17:35.858634  5440 net.cpp:444] loss <- label_data_1_split_1
I0716 18:17:35.858634  5440 net.cpp:418] loss -> loss
I0716 18:17:35.858634  5440 layer_factory.hpp:77] Creating layer loss
I0716 18:17:35.858634  5440 net.cpp:150] Setting up loss
I0716 18:17:35.858634  5440 net.cpp:157] Top shape: (1)
I0716 18:17:35.858634  5440 net.cpp:160]     with loss weight 1
I0716 18:17:35.858634  5440 net.cpp:165] Memory required for data: 61272208
I0716 18:17:35.858634  5440 net.cpp:226] loss needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:228] accuracy does not need backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] fc8 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] drop7 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu7 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] fc7 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] drop6 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu6 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] fc6 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] pool5 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu5 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] conv5 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu4 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] conv4 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu3 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] conv3 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] norm2 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] pool2 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu2 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] conv2 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] norm1 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] pool1 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] relu1 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:226] conv1 needs backward computation.
I0716 18:17:35.858634  5440 net.cpp:228] label_data_1_split does not need backward computation.
I0716 18:17:35.858634  5440 net.cpp:228] data does not need backward computation.
I0716 18:17:35.858634  5440 net.cpp:270] This network produces output accuracy
I0716 18:17:35.858634  5440 net.cpp:270] This network produces output loss
I0716 18:17:35.858634  5440 net.cpp:283] Network initialization done.
I0716 18:17:35.858634  5440 solver.cpp:60] Solver scaffolding done.
I0716 18:17:35.858634  5440 caffe.cpp:252] Starting Optimization
I0716 18:17:35.858634  5440 solver.cpp:279] Solving CaffeNet
I0716 18:17:35.858634  5440 solver.cpp:280] Learning Rate Policy: step
I0716 18:17:35.889891  5440 solver.cpp:337] Iteration 0, Testing net (#0)
I0716 18:18:29.854393  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5116
I0716 18:18:29.854931  5440 solver.cpp:404]     Test net output #1: loss = 0.699103 (* 1 = 0.699103 loss)
I0716 18:18:32.373124  5440 solver.cpp:228] Iteration 0, loss = 0.736528
I0716 18:18:32.373124  5440 solver.cpp:244]     Train net output #0: loss = 0.736528 (* 1 = 0.736528 loss)
I0716 18:18:32.373124  5440 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0716 18:18:55.240806  5440 solver.cpp:337] Iteration 10, Testing net (#0)
I0716 18:19:49.364054  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5116
I0716 18:19:49.364054  5440 solver.cpp:404]     Test net output #1: loss = 0.724797 (* 1 = 0.724797 loss)
I0716 18:20:14.658702  5440 solver.cpp:337] Iteration 20, Testing net (#0)
I0716 18:21:08.346907  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5118
I0716 18:21:08.346907  5440 solver.cpp:404]     Test net output #1: loss = 0.723394 (* 1 = 0.723394 loss)
I0716 18:21:10.823259  5440 solver.cpp:228] Iteration 20, loss = 0.610407
I0716 18:21:10.823259  5440 solver.cpp:244]     Train net output #0: loss = 0.610407 (* 1 = 0.610407 loss)
I0716 18:21:10.823761  5440 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0716 18:21:33.698153  5440 solver.cpp:337] Iteration 30, Testing net (#0)
I0716 18:22:27.381237  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5112
I0716 18:22:27.381237  5440 solver.cpp:404]     Test net output #1: loss = 0.70648 (* 1 = 0.70648 loss)
I0716 18:22:52.644392  5440 solver.cpp:337] Iteration 40, Testing net (#0)
I0716 18:23:46.339545  5440 solver.cpp:404]     Test net output #0: accuracy = 0.511
I0716 18:23:46.339545  5440 solver.cpp:404]     Test net output #1: loss = 0.742062 (* 1 = 0.742062 loss)
I0716 18:23:48.827141  5440 solver.cpp:228] Iteration 40, loss = 0.610389
I0716 18:23:48.827141  5440 solver.cpp:244]     Train net output #0: loss = 0.610389 (* 1 = 0.610389 loss)
I0716 18:23:48.827141  5440 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0716 18:24:11.620967  5440 solver.cpp:337] Iteration 50, Testing net (#0)
I0716 18:25:05.279253  5440 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0716 18:25:05.279253  5440 solver.cpp:404]     Test net output #1: loss = 0.729393 (* 1 = 0.729393 loss)
I0716 18:25:30.594693  5440 solver.cpp:337] Iteration 60, Testing net (#0)
I0716 18:26:24.370398  5440 solver.cpp:404]     Test net output #0: accuracy = 0.511
I0716 18:26:24.370398  5440 solver.cpp:404]     Test net output #1: loss = 0.737689 (* 1 = 0.737689 loss)
I0716 18:26:26.860833  5440 solver.cpp:228] Iteration 60, loss = 0.623292
I0716 18:26:26.860833  5440 solver.cpp:244]     Train net output #0: loss = 0.623292 (* 1 = 0.623292 loss)
I0716 18:26:26.860833  5440 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0716 18:26:49.591614  5440 solver.cpp:337] Iteration 70, Testing net (#0)
I0716 18:27:43.313051  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5116
I0716 18:27:43.313051  5440 solver.cpp:404]     Test net output #1: loss = 0.72361 (* 1 = 0.72361 loss)
I0716 18:28:08.555667  5440 solver.cpp:337] Iteration 80, Testing net (#0)
I0716 18:29:02.370838  5440 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0716 18:29:02.370838  5440 solver.cpp:404]     Test net output #1: loss = 0.702185 (* 1 = 0.702185 loss)
I0716 18:29:04.904894  5440 solver.cpp:228] Iteration 80, loss = 0.631526
I0716 18:29:04.904894  5440 solver.cpp:244]     Train net output #0: loss = 0.631526 (* 1 = 0.631526 loss)
I0716 18:29:04.904894  5440 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0716 18:29:27.717386  5440 solver.cpp:337] Iteration 90, Testing net (#0)
I0716 18:30:21.228011  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5104
I0716 18:30:21.228011  5440 solver.cpp:404]     Test net output #1: loss = 0.688903 (* 1 = 0.688903 loss)
I0716 18:30:46.584933  5440 solver.cpp:337] Iteration 100, Testing net (#0)
I0716 18:31:40.106454  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5108
I0716 18:31:40.106454  5440 solver.cpp:404]     Test net output #1: loss = 0.611601 (* 1 = 0.611601 loss)
I0716 18:31:42.613314  5440 solver.cpp:228] Iteration 100, loss = 0.456403
I0716 18:31:42.613314  5440 solver.cpp:244]     Train net output #0: loss = 0.456403 (* 1 = 0.456403 loss)
I0716 18:31:42.613314  5440 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0716 18:32:05.335755  5440 solver.cpp:337] Iteration 110, Testing net (#0)
I0716 18:32:59.319185  5440 solver.cpp:404]     Test net output #0: accuracy = 0.511
I0716 18:32:59.319185  5440 solver.cpp:404]     Test net output #1: loss = 0.553687 (* 1 = 0.553687 loss)
I0716 18:33:24.557986  5440 solver.cpp:337] Iteration 120, Testing net (#0)
I0716 18:34:18.111090  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8312
I0716 18:34:18.111090  5440 solver.cpp:404]     Test net output #1: loss = 0.481828 (* 1 = 0.481828 loss)
I0716 18:34:20.583374  5440 solver.cpp:228] Iteration 120, loss = 0.406977
I0716 18:34:20.583374  5440 solver.cpp:244]     Train net output #0: loss = 0.406977 (* 1 = 0.406977 loss)
I0716 18:34:20.583374  5440 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0716 18:34:43.429033  5440 solver.cpp:337] Iteration 130, Testing net (#0)
I0716 18:35:36.893664  5440 solver.cpp:404]     Test net output #0: accuracy = 0.682
I0716 18:35:36.893664  5440 solver.cpp:404]     Test net output #1: loss = 1.21792 (* 1 = 1.21792 loss)
I0716 18:36:02.118599  5440 solver.cpp:337] Iteration 140, Testing net (#0)
I0716 18:36:55.550662  5440 solver.cpp:404]     Test net output #0: accuracy = 0.6672
I0716 18:36:55.550662  5440 solver.cpp:404]     Test net output #1: loss = 0.577627 (* 1 = 0.577627 loss)
I0716 18:36:57.997494  5440 solver.cpp:228] Iteration 140, loss = 0.51272
I0716 18:36:57.997494  5440 solver.cpp:244]     Train net output #0: loss = 0.51272 (* 1 = 0.51272 loss)
I0716 18:36:57.997494  5440 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0716 18:37:20.773100  5440 solver.cpp:337] Iteration 150, Testing net (#0)
I0716 18:38:14.108358  5440 solver.cpp:404]     Test net output #0: accuracy = 0.7522
I0716 18:38:14.108894  5440 solver.cpp:404]     Test net output #1: loss = 0.53853 (* 1 = 0.53853 loss)
I0716 18:38:39.375639  5440 solver.cpp:337] Iteration 160, Testing net (#0)
I0716 18:39:32.988797  5440 solver.cpp:404]     Test net output #0: accuracy = 0.7738
I0716 18:39:32.988797  5440 solver.cpp:404]     Test net output #1: loss = 0.534609 (* 1 = 0.534609 loss)
I0716 18:39:35.445781  5440 solver.cpp:228] Iteration 160, loss = 0.575107
I0716 18:39:35.445781  5440 solver.cpp:244]     Train net output #0: loss = 0.575107 (* 1 = 0.575107 loss)
I0716 18:39:35.445781  5440 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0716 18:39:58.255980  5440 solver.cpp:337] Iteration 170, Testing net (#0)
I0716 18:40:52.244441  5440 solver.cpp:404]     Test net output #0: accuracy = 0.5778
I0716 18:40:52.244441  5440 solver.cpp:404]     Test net output #1: loss = 0.58645 (* 1 = 0.58645 loss)
I0716 18:41:17.929764  5440 solver.cpp:337] Iteration 180, Testing net (#0)
I0716 18:42:11.964644  5440 solver.cpp:404]     Test net output #0: accuracy = 0.7428
I0716 18:42:11.964644  5440 solver.cpp:404]     Test net output #1: loss = 0.612184 (* 1 = 0.612184 loss)
I0716 18:42:14.456899  5440 solver.cpp:228] Iteration 180, loss = 0.435748
I0716 18:42:14.456899  5440 solver.cpp:244]     Train net output #0: loss = 0.435748 (* 1 = 0.435748 loss)
I0716 18:42:14.456899  5440 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0716 18:42:37.195480  5440 solver.cpp:337] Iteration 190, Testing net (#0)
I0716 18:43:30.630147  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8218
I0716 18:43:30.630147  5440 solver.cpp:404]     Test net output #1: loss = 0.468421 (* 1 = 0.468421 loss)
I0716 18:43:55.922981  5440 solver.cpp:337] Iteration 200, Testing net (#0)
I0716 18:44:49.571096  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8856
I0716 18:44:49.571096  5440 solver.cpp:404]     Test net output #1: loss = 0.401003 (* 1 = 0.401003 loss)
I0716 18:44:52.131526  5440 solver.cpp:228] Iteration 200, loss = 0.343584
I0716 18:44:52.131526  5440 solver.cpp:244]     Train net output #0: loss = 0.343584 (* 1 = 0.343584 loss)
I0716 18:44:52.131526  5440 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0716 18:45:14.857954  5440 solver.cpp:337] Iteration 210, Testing net (#0)
I0716 18:46:08.468679  5440 solver.cpp:404]     Test net output #0: accuracy = 0.7404
I0716 18:46:08.468679  5440 solver.cpp:404]     Test net output #1: loss = 0.521422 (* 1 = 0.521422 loss)
I0716 18:46:33.635928  5440 solver.cpp:337] Iteration 220, Testing net (#0)
I0716 18:47:27.120745  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8934
I0716 18:47:27.120745  5440 solver.cpp:404]     Test net output #1: loss = 0.360793 (* 1 = 0.360793 loss)
I0716 18:47:29.598058  5440 solver.cpp:228] Iteration 220, loss = 0.303155
I0716 18:47:29.598058  5440 solver.cpp:244]     Train net output #0: loss = 0.303155 (* 1 = 0.303155 loss)
I0716 18:47:29.598058  5440 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0716 18:47:52.374919  5440 solver.cpp:337] Iteration 230, Testing net (#0)
I0716 18:48:45.600648  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8678
I0716 18:48:45.600648  5440 solver.cpp:404]     Test net output #1: loss = 0.362184 (* 1 = 0.362184 loss)
I0716 18:49:10.834795  5440 solver.cpp:337] Iteration 240, Testing net (#0)
I0716 18:50:04.176657  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8708
I0716 18:50:04.176657  5440 solver.cpp:404]     Test net output #1: loss = 0.378201 (* 1 = 0.378201 loss)
I0716 18:50:06.650166  5440 solver.cpp:228] Iteration 240, loss = 0.318358
I0716 18:50:06.650166  5440 solver.cpp:244]     Train net output #0: loss = 0.318359 (* 1 = 0.318359 loss)
I0716 18:50:06.650166  5440 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0716 18:50:29.381005  5440 solver.cpp:337] Iteration 250, Testing net (#0)
I0716 18:51:22.828127  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9014
I0716 18:51:22.828127  5440 solver.cpp:404]     Test net output #1: loss = 0.325838 (* 1 = 0.325838 loss)
I0716 18:51:48.057019  5440 solver.cpp:337] Iteration 260, Testing net (#0)
I0716 18:52:41.402918  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8906
I0716 18:52:41.402918  5440 solver.cpp:404]     Test net output #1: loss = 0.327171 (* 1 = 0.327171 loss)
I0716 18:52:43.840191  5440 solver.cpp:228] Iteration 260, loss = 0.284214
I0716 18:52:43.840191  5440 solver.cpp:244]     Train net output #0: loss = 0.284214 (* 1 = 0.284214 loss)
I0716 18:52:43.840191  5440 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0716 18:53:06.580622  5440 solver.cpp:337] Iteration 270, Testing net (#0)
I0716 18:53:59.758096  5440 solver.cpp:404]     Test net output #0: accuracy = 0.865
I0716 18:53:59.758096  5440 solver.cpp:404]     Test net output #1: loss = 0.365388 (* 1 = 0.365388 loss)
I0716 18:54:25.032652  5440 solver.cpp:337] Iteration 280, Testing net (#0)
I0716 18:55:18.376104  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8794
I0716 18:55:18.376104  5440 solver.cpp:404]     Test net output #1: loss = 0.337887 (* 1 = 0.337887 loss)
I0716 18:55:20.806758  5440 solver.cpp:228] Iteration 280, loss = 0.377289
I0716 18:55:20.806758  5440 solver.cpp:244]     Train net output #0: loss = 0.37729 (* 1 = 0.37729 loss)
I0716 18:55:20.806758  5440 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0716 18:55:43.599179  5440 solver.cpp:337] Iteration 290, Testing net (#0)
I0716 18:56:36.826164  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8638
I0716 18:56:36.826164  5440 solver.cpp:404]     Test net output #1: loss = 0.335141 (* 1 = 0.335141 loss)
I0716 18:57:02.061547  5440 solver.cpp:337] Iteration 300, Testing net (#0)
I0716 18:57:55.347784  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8346
I0716 18:57:55.347784  5440 solver.cpp:404]     Test net output #1: loss = 0.50248 (* 1 = 0.50248 loss)
I0716 18:57:57.802942  5440 solver.cpp:228] Iteration 300, loss = 0.360176
I0716 18:57:57.802942  5440 solver.cpp:244]     Train net output #0: loss = 0.360176 (* 1 = 0.360176 loss)
I0716 18:57:57.802942  5440 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0716 18:58:20.555080  5440 solver.cpp:337] Iteration 310, Testing net (#0)
I0716 18:59:14.038558  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8996
I0716 18:59:14.038558  5440 solver.cpp:404]     Test net output #1: loss = 0.308554 (* 1 = 0.308554 loss)
I0716 18:59:39.267592  5440 solver.cpp:337] Iteration 320, Testing net (#0)
I0716 19:00:32.482986  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8888
I0716 19:00:32.482986  5440 solver.cpp:404]     Test net output #1: loss = 0.321795 (* 1 = 0.321795 loss)
I0716 19:00:34.929363  5440 solver.cpp:228] Iteration 320, loss = 0.352676
I0716 19:00:34.929363  5440 solver.cpp:244]     Train net output #0: loss = 0.352676 (* 1 = 0.352676 loss)
I0716 19:00:34.929363  5440 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0716 19:00:57.618206  5440 solver.cpp:337] Iteration 330, Testing net (#0)
I0716 19:01:50.768692  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8716
I0716 19:01:50.768692  5440 solver.cpp:404]     Test net output #1: loss = 0.471954 (* 1 = 0.471954 loss)
I0716 19:02:16.000082  5440 solver.cpp:337] Iteration 340, Testing net (#0)
I0716 19:03:09.107640  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8958
I0716 19:03:09.107640  5440 solver.cpp:404]     Test net output #1: loss = 0.348396 (* 1 = 0.348396 loss)
I0716 19:03:11.568493  5440 solver.cpp:228] Iteration 340, loss = 0.219967
I0716 19:03:11.568493  5440 solver.cpp:244]     Train net output #0: loss = 0.219968 (* 1 = 0.219968 loss)
I0716 19:03:11.568493  5440 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0716 19:03:34.316200  5440 solver.cpp:337] Iteration 350, Testing net (#0)
I0716 19:04:27.470763  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8566
I0716 19:04:27.471263  5440 solver.cpp:404]     Test net output #1: loss = 0.363199 (* 1 = 0.363199 loss)
I0716 19:04:52.634996  5440 solver.cpp:337] Iteration 360, Testing net (#0)
I0716 19:05:45.833184  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8648
I0716 19:05:45.833184  5440 solver.cpp:404]     Test net output #1: loss = 0.356857 (* 1 = 0.356857 loss)
I0716 19:05:48.311491  5440 solver.cpp:228] Iteration 360, loss = 0.326667
I0716 19:05:48.311491  5440 solver.cpp:244]     Train net output #0: loss = 0.326668 (* 1 = 0.326668 loss)
I0716 19:05:48.311491  5440 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0716 19:06:11.108932  5440 solver.cpp:337] Iteration 370, Testing net (#0)
I0716 19:07:04.287796  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8474
I0716 19:07:04.287796  5440 solver.cpp:404]     Test net output #1: loss = 0.430452 (* 1 = 0.430452 loss)
I0716 19:07:29.636792  5440 solver.cpp:337] Iteration 380, Testing net (#0)
I0716 19:08:22.777695  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8974
I0716 19:08:22.778231  5440 solver.cpp:404]     Test net output #1: loss = 0.286507 (* 1 = 0.286507 loss)
I0716 19:08:25.209301  5440 solver.cpp:228] Iteration 380, loss = 0.180887
I0716 19:08:25.209301  5440 solver.cpp:244]     Train net output #0: loss = 0.180887 (* 1 = 0.180887 loss)
I0716 19:08:25.209301  5440 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0716 19:08:47.915014  5440 solver.cpp:337] Iteration 390, Testing net (#0)
I0716 19:09:40.925369  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9052
I0716 19:09:40.925369  5440 solver.cpp:404]     Test net output #1: loss = 0.280989 (* 1 = 0.280989 loss)
I0716 19:10:06.135785  5440 solver.cpp:337] Iteration 400, Testing net (#0)
I0716 19:10:59.062289  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9126
I0716 19:10:59.062289  5440 solver.cpp:404]     Test net output #1: loss = 0.314729 (* 1 = 0.314729 loss)
I0716 19:11:01.533128  5440 solver.cpp:228] Iteration 400, loss = 0.27583
I0716 19:11:01.533128  5440 solver.cpp:244]     Train net output #0: loss = 0.27583 (* 1 = 0.27583 loss)
I0716 19:11:01.533128  5440 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0716 19:11:24.228768  5440 solver.cpp:337] Iteration 410, Testing net (#0)
I0716 19:12:17.421638  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8504
I0716 19:12:17.421638  5440 solver.cpp:404]     Test net output #1: loss = 0.538198 (* 1 = 0.538198 loss)
I0716 19:12:42.554354  5440 solver.cpp:337] Iteration 420, Testing net (#0)
I0716 19:13:35.610821  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8866
I0716 19:13:35.610821  5440 solver.cpp:404]     Test net output #1: loss = 0.318637 (* 1 = 0.318637 loss)
I0716 19:13:38.077448  5440 solver.cpp:228] Iteration 420, loss = 0.260654
I0716 19:13:38.077448  5440 solver.cpp:244]     Train net output #0: loss = 0.260654 (* 1 = 0.260654 loss)
I0716 19:13:38.077448  5440 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0716 19:14:01.019004  5440 solver.cpp:337] Iteration 430, Testing net (#0)
I0716 19:14:54.276000  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8768
I0716 19:14:54.276540  5440 solver.cpp:404]     Test net output #1: loss = 0.455521 (* 1 = 0.455521 loss)
I0716 19:15:19.458439  5440 solver.cpp:337] Iteration 440, Testing net (#0)
I0716 19:16:12.629405  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9038
I0716 19:16:12.629904  5440 solver.cpp:404]     Test net output #1: loss = 0.287676 (* 1 = 0.287676 loss)
I0716 19:16:15.075764  5440 solver.cpp:228] Iteration 440, loss = 0.235634
I0716 19:16:15.076266  5440 solver.cpp:244]     Train net output #0: loss = 0.235635 (* 1 = 0.235635 loss)
I0716 19:16:15.076266  5440 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0716 19:16:37.861733  5440 solver.cpp:337] Iteration 450, Testing net (#0)
I0716 19:17:30.916891  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9066
I0716 19:17:30.916891  5440 solver.cpp:404]     Test net output #1: loss = 0.29956 (* 1 = 0.29956 loss)
I0716 19:17:56.064828  5440 solver.cpp:337] Iteration 460, Testing net (#0)
I0716 19:18:49.026144  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9012
I0716 19:18:49.026680  5440 solver.cpp:404]     Test net output #1: loss = 0.273016 (* 1 = 0.273016 loss)
I0716 19:18:51.511359  5440 solver.cpp:228] Iteration 460, loss = 0.256454
I0716 19:18:51.511359  5440 solver.cpp:244]     Train net output #0: loss = 0.256454 (* 1 = 0.256454 loss)
I0716 19:18:51.511359  5440 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0716 19:19:14.183141  5440 solver.cpp:337] Iteration 470, Testing net (#0)
I0716 19:20:08.968011  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9078
I0716 19:20:08.968011  5440 solver.cpp:404]     Test net output #1: loss = 0.313419 (* 1 = 0.313419 loss)
I0716 19:20:34.748450  5440 solver.cpp:337] Iteration 480, Testing net (#0)
I0716 19:21:28.799338  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8444
I0716 19:21:28.799338  5440 solver.cpp:404]     Test net output #1: loss = 0.375184 (* 1 = 0.375184 loss)
I0716 19:21:31.251142  5440 solver.cpp:228] Iteration 480, loss = 0.446955
I0716 19:21:31.251142  5440 solver.cpp:244]     Train net output #0: loss = 0.446955 (* 1 = 0.446955 loss)
I0716 19:21:31.251142  5440 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0716 19:21:54.834931  5440 solver.cpp:337] Iteration 490, Testing net (#0)
I0716 19:22:48.381116  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9038
I0716 19:22:48.381116  5440 solver.cpp:404]     Test net output #1: loss = 0.283188 (* 1 = 0.283188 loss)
I0716 19:23:13.576467  5440 solver.cpp:337] Iteration 500, Testing net (#0)
I0716 19:24:06.651126  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9086
I0716 19:24:06.651126  5440 solver.cpp:404]     Test net output #1: loss = 0.310084 (* 1 = 0.310084 loss)
I0716 19:24:09.099190  5440 solver.cpp:228] Iteration 500, loss = 0.333881
I0716 19:24:09.099190  5440 solver.cpp:244]     Train net output #0: loss = 0.333881 (* 1 = 0.333881 loss)
I0716 19:24:09.099190  5440 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0716 19:24:31.681000  5440 solver.cpp:337] Iteration 510, Testing net (#0)
I0716 19:25:24.746997  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9044
I0716 19:25:24.746997  5440 solver.cpp:404]     Test net output #1: loss = 0.280279 (* 1 = 0.280279 loss)
I0716 19:25:49.921278  5440 solver.cpp:337] Iteration 520, Testing net (#0)
I0716 19:26:43.179461  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9106
I0716 19:26:43.179461  5440 solver.cpp:404]     Test net output #1: loss = 0.256941 (* 1 = 0.256941 loss)
I0716 19:26:45.651600  5440 solver.cpp:228] Iteration 520, loss = 0.220921
I0716 19:26:45.651600  5440 solver.cpp:244]     Train net output #0: loss = 0.220922 (* 1 = 0.220922 loss)
I0716 19:26:45.651600  5440 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0716 19:27:08.363983  5440 solver.cpp:337] Iteration 530, Testing net (#0)
I0716 19:28:01.546003  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9134
I0716 19:28:01.546003  5440 solver.cpp:404]     Test net output #1: loss = 0.288145 (* 1 = 0.288145 loss)
I0716 19:28:26.680472  5440 solver.cpp:337] Iteration 540, Testing net (#0)
I0716 19:29:20.878135  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8772
I0716 19:29:20.878135  5440 solver.cpp:404]     Test net output #1: loss = 0.353538 (* 1 = 0.353538 loss)
I0716 19:29:23.321393  5440 solver.cpp:228] Iteration 540, loss = 0.248817
I0716 19:29:23.321393  5440 solver.cpp:244]     Train net output #0: loss = 0.248817 (* 1 = 0.248817 loss)
I0716 19:29:23.321393  5440 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0716 19:29:46.020321  5440 solver.cpp:337] Iteration 550, Testing net (#0)
I0716 19:30:39.175549  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8706
I0716 19:30:39.175549  5440 solver.cpp:404]     Test net output #1: loss = 0.353681 (* 1 = 0.353681 loss)
I0716 19:31:04.265244  5440 solver.cpp:337] Iteration 560, Testing net (#0)
I0716 19:31:57.444067  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9176
I0716 19:31:57.444067  5440 solver.cpp:404]     Test net output #1: loss = 0.286208 (* 1 = 0.286208 loss)
I0716 19:31:59.894968  5440 solver.cpp:228] Iteration 560, loss = 0.150492
I0716 19:31:59.894968  5440 solver.cpp:244]     Train net output #0: loss = 0.150493 (* 1 = 0.150493 loss)
I0716 19:31:59.894968  5440 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0716 19:32:22.705879  5440 solver.cpp:337] Iteration 570, Testing net (#0)
I0716 19:33:15.778060  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9164
I0716 19:33:15.778060  5440 solver.cpp:404]     Test net output #1: loss = 0.251813 (* 1 = 0.251813 loss)
I0716 19:33:40.970999  5440 solver.cpp:337] Iteration 580, Testing net (#0)
I0716 19:34:34.151885  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8908
I0716 19:34:34.151885  5440 solver.cpp:404]     Test net output #1: loss = 0.291618 (* 1 = 0.291618 loss)
I0716 19:34:36.646682  5440 solver.cpp:228] Iteration 580, loss = 0.201554
I0716 19:34:36.646682  5440 solver.cpp:244]     Train net output #0: loss = 0.201555 (* 1 = 0.201555 loss)
I0716 19:34:36.646682  5440 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0716 19:34:59.452934  5440 solver.cpp:337] Iteration 590, Testing net (#0)
I0716 19:35:52.666703  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9084
I0716 19:35:52.666703  5440 solver.cpp:404]     Test net output #1: loss = 0.295089 (* 1 = 0.295089 loss)
I0716 19:36:17.795414  5440 solver.cpp:337] Iteration 600, Testing net (#0)
I0716 19:37:10.982769  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9032
I0716 19:37:10.982769  5440 solver.cpp:404]     Test net output #1: loss = 0.275608 (* 1 = 0.275608 loss)
I0716 19:37:13.454044  5440 solver.cpp:228] Iteration 600, loss = 0.181737
I0716 19:37:13.454044  5440 solver.cpp:244]     Train net output #0: loss = 0.181737 (* 1 = 0.181737 loss)
I0716 19:37:13.454044  5440 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0716 19:37:36.220506  5440 solver.cpp:337] Iteration 610, Testing net (#0)
I0716 19:38:29.148309  5440 solver.cpp:404]     Test net output #0: accuracy = 0.913
I0716 19:38:29.148309  5440 solver.cpp:404]     Test net output #1: loss = 0.249231 (* 1 = 0.249231 loss)
I0716 19:38:54.319941  5440 solver.cpp:337] Iteration 620, Testing net (#0)
I0716 19:39:47.447964  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9142
I0716 19:39:47.447964  5440 solver.cpp:404]     Test net output #1: loss = 0.277542 (* 1 = 0.277542 loss)
I0716 19:39:49.894448  5440 solver.cpp:228] Iteration 620, loss = 0.188049
I0716 19:39:49.894448  5440 solver.cpp:244]     Train net output #0: loss = 0.188049 (* 1 = 0.188049 loss)
I0716 19:39:49.894448  5440 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0716 19:40:12.582023  5440 solver.cpp:337] Iteration 630, Testing net (#0)
I0716 19:41:05.658701  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8448
I0716 19:41:05.658701  5440 solver.cpp:404]     Test net output #1: loss = 0.413752 (* 1 = 0.413752 loss)
I0716 19:41:30.799209  5440 solver.cpp:337] Iteration 640, Testing net (#0)
I0716 19:42:23.903749  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9034
I0716 19:42:23.904284  5440 solver.cpp:404]     Test net output #1: loss = 0.276951 (* 1 = 0.276951 loss)
I0716 19:42:26.338289  5440 solver.cpp:228] Iteration 640, loss = 0.249397
I0716 19:42:26.338289  5440 solver.cpp:244]     Train net output #0: loss = 0.249397 (* 1 = 0.249397 loss)
I0716 19:42:26.338289  5440 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0716 19:42:49.027721  5440 solver.cpp:337] Iteration 650, Testing net (#0)
I0716 19:43:42.126530  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9192
I0716 19:43:42.126530  5440 solver.cpp:404]     Test net output #1: loss = 0.257802 (* 1 = 0.257802 loss)
I0716 19:44:07.565842  5440 solver.cpp:337] Iteration 660, Testing net (#0)
I0716 19:45:00.695875  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9178
I0716 19:45:00.695875  5440 solver.cpp:404]     Test net output #1: loss = 0.235722 (* 1 = 0.235722 loss)
I0716 19:45:03.154088  5440 solver.cpp:228] Iteration 660, loss = 0.190483
I0716 19:45:03.154088  5440 solver.cpp:244]     Train net output #0: loss = 0.190483 (* 1 = 0.190483 loss)
I0716 19:45:03.154088  5440 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0716 19:45:25.861883  5440 solver.cpp:337] Iteration 670, Testing net (#0)
I0716 19:46:18.963620  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8958
I0716 19:46:18.963620  5440 solver.cpp:404]     Test net output #1: loss = 0.406368 (* 1 = 0.406368 loss)
I0716 19:46:44.159567  5440 solver.cpp:337] Iteration 680, Testing net (#0)
I0716 19:47:37.238749  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9286
I0716 19:47:37.238749  5440 solver.cpp:404]     Test net output #1: loss = 0.241746 (* 1 = 0.241746 loss)
I0716 19:47:39.664012  5440 solver.cpp:228] Iteration 680, loss = 0.220722
I0716 19:47:39.664012  5440 solver.cpp:244]     Train net output #0: loss = 0.220722 (* 1 = 0.220722 loss)
I0716 19:47:39.664012  5440 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0716 19:48:02.367614  5440 solver.cpp:337] Iteration 690, Testing net (#0)
I0716 19:48:55.495322  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9138
I0716 19:48:55.495322  5440 solver.cpp:404]     Test net output #1: loss = 0.252727 (* 1 = 0.252727 loss)
I0716 19:49:20.683022  5440 solver.cpp:337] Iteration 700, Testing net (#0)
I0716 19:50:13.746794  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9238
I0716 19:50:13.746794  5440 solver.cpp:404]     Test net output #1: loss = 0.297286 (* 1 = 0.297286 loss)
I0716 19:50:16.197691  5440 solver.cpp:228] Iteration 700, loss = 0.303268
I0716 19:50:16.197691  5440 solver.cpp:244]     Train net output #0: loss = 0.303268 (* 1 = 0.303268 loss)
I0716 19:50:16.197691  5440 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0716 19:50:38.948024  5440 solver.cpp:337] Iteration 710, Testing net (#0)
I0716 19:51:32.130965  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9154
I0716 19:51:32.130965  5440 solver.cpp:404]     Test net output #1: loss = 0.240118 (* 1 = 0.240118 loss)
I0716 19:51:57.286651  5440 solver.cpp:337] Iteration 720, Testing net (#0)
I0716 19:52:50.554177  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9042
I0716 19:52:50.554177  5440 solver.cpp:404]     Test net output #1: loss = 0.262627 (* 1 = 0.262627 loss)
I0716 19:52:52.980140  5440 solver.cpp:228] Iteration 720, loss = 0.238125
I0716 19:52:52.980140  5440 solver.cpp:244]     Train net output #0: loss = 0.238126 (* 1 = 0.238126 loss)
I0716 19:52:52.980140  5440 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0716 19:53:15.636924  5440 solver.cpp:337] Iteration 730, Testing net (#0)
I0716 19:54:08.789410  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9114
I0716 19:54:08.789410  5440 solver.cpp:404]     Test net output #1: loss = 0.244979 (* 1 = 0.244979 loss)
I0716 19:54:33.872803  5440 solver.cpp:337] Iteration 740, Testing net (#0)
I0716 19:55:26.818775  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9108
I0716 19:55:26.818775  5440 solver.cpp:404]     Test net output #1: loss = 0.264928 (* 1 = 0.264928 loss)
I0716 19:55:29.286801  5440 solver.cpp:228] Iteration 740, loss = 0.203734
I0716 19:55:29.286801  5440 solver.cpp:244]     Train net output #0: loss = 0.203734 (* 1 = 0.203734 loss)
I0716 19:55:29.286801  5440 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0716 19:55:52.235353  5440 solver.cpp:337] Iteration 750, Testing net (#0)
I0716 19:56:45.200657  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9214
I0716 19:56:45.200657  5440 solver.cpp:404]     Test net output #1: loss = 0.233703 (* 1 = 0.233703 loss)
I0716 19:57:10.311867  5440 solver.cpp:337] Iteration 760, Testing net (#0)
I0716 19:58:03.392065  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9128
I0716 19:58:03.392065  5440 solver.cpp:404]     Test net output #1: loss = 0.262383 (* 1 = 0.262383 loss)
I0716 19:58:05.853469  5440 solver.cpp:228] Iteration 760, loss = 0.139391
I0716 19:58:05.853469  5440 solver.cpp:244]     Train net output #0: loss = 0.139391 (* 1 = 0.139391 loss)
I0716 19:58:05.853469  5440 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0716 19:58:28.559774  5440 solver.cpp:337] Iteration 770, Testing net (#0)
I0716 19:59:21.785064  5440 solver.cpp:404]     Test net output #0: accuracy = 0.911
I0716 19:59:21.785064  5440 solver.cpp:404]     Test net output #1: loss = 0.30535 (* 1 = 0.30535 loss)
I0716 19:59:46.996026  5440 solver.cpp:337] Iteration 780, Testing net (#0)
I0716 20:00:40.014611  5440 solver.cpp:404]     Test net output #0: accuracy = 0.926
I0716 20:00:40.014611  5440 solver.cpp:404]     Test net output #1: loss = 0.227135 (* 1 = 0.227135 loss)
I0716 20:00:42.506738  5440 solver.cpp:228] Iteration 780, loss = 0.15202
I0716 20:00:42.506738  5440 solver.cpp:244]     Train net output #0: loss = 0.15202 (* 1 = 0.15202 loss)
I0716 20:00:42.506738  5440 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0716 20:01:05.198613  5440 solver.cpp:337] Iteration 790, Testing net (#0)
I0716 20:01:58.324591  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9234
I0716 20:01:58.324591  5440 solver.cpp:404]     Test net output #1: loss = 0.224096 (* 1 = 0.224096 loss)
I0716 20:02:23.481590  5440 solver.cpp:337] Iteration 800, Testing net (#0)
I0716 20:03:16.842382  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8988
I0716 20:03:16.842382  5440 solver.cpp:404]     Test net output #1: loss = 0.347242 (* 1 = 0.347242 loss)
I0716 20:03:19.316772  5440 solver.cpp:228] Iteration 800, loss = 0.173354
I0716 20:03:19.316772  5440 solver.cpp:244]     Train net output #0: loss = 0.173354 (* 1 = 0.173354 loss)
I0716 20:03:19.316772  5440 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0716 20:03:42.088906  5440 solver.cpp:337] Iteration 810, Testing net (#0)
I0716 20:04:35.129317  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8984
I0716 20:04:35.129856  5440 solver.cpp:404]     Test net output #1: loss = 0.269306 (* 1 = 0.269306 loss)
I0716 20:05:00.323226  5440 solver.cpp:337] Iteration 820, Testing net (#0)
I0716 20:05:53.442581  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9224
I0716 20:05:53.442581  5440 solver.cpp:404]     Test net output #1: loss = 0.226011 (* 1 = 0.226011 loss)
I0716 20:05:55.896653  5440 solver.cpp:228] Iteration 820, loss = 0.260971
I0716 20:05:55.896653  5440 solver.cpp:244]     Train net output #0: loss = 0.260971 (* 1 = 0.260971 loss)
I0716 20:05:55.896653  5440 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0716 20:06:19.200196  5440 solver.cpp:337] Iteration 830, Testing net (#0)
I0716 20:07:13.726001  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9194
I0716 20:07:13.726001  5440 solver.cpp:404]     Test net output #1: loss = 0.248635 (* 1 = 0.248635 loss)
I0716 20:07:38.902099  5440 solver.cpp:337] Iteration 840, Testing net (#0)
I0716 20:08:31.934208  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9296
I0716 20:08:31.934208  5440 solver.cpp:404]     Test net output #1: loss = 0.238069 (* 1 = 0.238069 loss)
I0716 20:08:34.399401  5440 solver.cpp:228] Iteration 840, loss = 0.103775
I0716 20:08:34.399401  5440 solver.cpp:244]     Train net output #0: loss = 0.103775 (* 1 = 0.103775 loss)
I0716 20:08:34.399401  5440 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0716 20:08:57.046553  5440 solver.cpp:337] Iteration 850, Testing net (#0)
I0716 20:09:50.266254  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9278
I0716 20:09:50.266254  5440 solver.cpp:404]     Test net output #1: loss = 0.225175 (* 1 = 0.225175 loss)
I0716 20:10:15.504338  5440 solver.cpp:337] Iteration 860, Testing net (#0)
I0716 20:11:08.605101  5440 solver.cpp:404]     Test net output #0: accuracy = 0.8896
I0716 20:11:08.605639  5440 solver.cpp:404]     Test net output #1: loss = 0.421258 (* 1 = 0.421258 loss)
I0716 20:11:11.103996  5440 solver.cpp:228] Iteration 860, loss = 0.340038
I0716 20:11:11.103996  5440 solver.cpp:244]     Train net output #0: loss = 0.340038 (* 1 = 0.340038 loss)
I0716 20:11:11.103996  5440 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0716 20:11:33.926832  5440 solver.cpp:337] Iteration 870, Testing net (#0)
I0716 20:12:27.216342  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9256
I0716 20:12:27.216342  5440 solver.cpp:404]     Test net output #1: loss = 0.217833 (* 1 = 0.217833 loss)
I0716 20:12:52.388203  5440 solver.cpp:337] Iteration 880, Testing net (#0)
I0716 20:13:45.396534  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9194
I0716 20:13:45.397073  5440 solver.cpp:404]     Test net output #1: loss = 0.23491 (* 1 = 0.23491 loss)
I0716 20:13:47.876020  5440 solver.cpp:228] Iteration 880, loss = 0.186645
I0716 20:13:47.876020  5440 solver.cpp:244]     Train net output #0: loss = 0.186645 (* 1 = 0.186645 loss)
I0716 20:13:47.876020  5440 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0716 20:14:10.621657  5440 solver.cpp:337] Iteration 890, Testing net (#0)
I0716 20:15:03.755321  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9132
I0716 20:15:03.755321  5440 solver.cpp:404]     Test net output #1: loss = 0.248475 (* 1 = 0.248475 loss)
I0716 20:15:29.033815  5440 solver.cpp:337] Iteration 900, Testing net (#0)
I0716 20:16:22.163249  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9124
I0716 20:16:22.163249  5440 solver.cpp:404]     Test net output #1: loss = 0.292271 (* 1 = 0.292271 loss)
I0716 20:16:24.864958  5440 solver.cpp:228] Iteration 900, loss = 0.208976
I0716 20:16:24.864958  5440 solver.cpp:244]     Train net output #0: loss = 0.208977 (* 1 = 0.208977 loss)
I0716 20:16:24.864958  5440 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0716 20:16:47.662572  5440 solver.cpp:337] Iteration 910, Testing net (#0)
I0716 20:17:40.670346  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9236
I0716 20:17:40.670346  5440 solver.cpp:404]     Test net output #1: loss = 0.320398 (* 1 = 0.320398 loss)
I0716 20:18:05.824697  5440 solver.cpp:337] Iteration 920, Testing net (#0)
I0716 20:18:58.843394  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9228
I0716 20:18:58.843394  5440 solver.cpp:404]     Test net output #1: loss = 0.238853 (* 1 = 0.238853 loss)
I0716 20:19:01.294554  5440 solver.cpp:228] Iteration 920, loss = 0.178624
I0716 20:19:01.294554  5440 solver.cpp:244]     Train net output #0: loss = 0.178624 (* 1 = 0.178624 loss)
I0716 20:19:01.294554  5440 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0716 20:19:24.035356  5440 solver.cpp:337] Iteration 930, Testing net (#0)
I0716 20:20:17.025871  5440 solver.cpp:404]     Test net output #0: accuracy = 0.916
I0716 20:20:17.025871  5440 solver.cpp:404]     Test net output #1: loss = 0.26391 (* 1 = 0.26391 loss)
I0716 20:20:42.214860  5440 solver.cpp:337] Iteration 940, Testing net (#0)
I0716 20:21:35.281047  5440 solver.cpp:404]     Test net output #0: accuracy = 0.919
I0716 20:21:35.281047  5440 solver.cpp:404]     Test net output #1: loss = 0.233645 (* 1 = 0.233645 loss)
I0716 20:21:37.743661  5440 solver.cpp:228] Iteration 940, loss = 0.165584
I0716 20:21:37.743661  5440 solver.cpp:244]     Train net output #0: loss = 0.165585 (* 1 = 0.165585 loss)
I0716 20:21:37.743661  5440 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0716 20:22:00.463070  5440 solver.cpp:337] Iteration 950, Testing net (#0)
I0716 20:22:53.533541  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9336
I0716 20:22:53.533541  5440 solver.cpp:404]     Test net output #1: loss = 0.261723 (* 1 = 0.261723 loss)
I0716 20:23:18.676057  5440 solver.cpp:337] Iteration 960, Testing net (#0)
I0716 20:24:11.698696  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9288
I0716 20:24:11.698696  5440 solver.cpp:404]     Test net output #1: loss = 0.22805 (* 1 = 0.22805 loss)
I0716 20:24:14.145198  5440 solver.cpp:228] Iteration 960, loss = 0.215154
I0716 20:24:14.145198  5440 solver.cpp:244]     Train net output #0: loss = 0.215154 (* 1 = 0.215154 loss)
I0716 20:24:14.145198  5440 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0716 20:24:36.862244  5440 solver.cpp:337] Iteration 970, Testing net (#0)
I0716 20:25:29.903987  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9236
I0716 20:25:29.904523  5440 solver.cpp:404]     Test net output #1: loss = 0.249339 (* 1 = 0.249339 loss)
I0716 20:25:55.028950  5440 solver.cpp:337] Iteration 980, Testing net (#0)
I0716 20:26:48.069538  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9242
I0716 20:26:48.069538  5440 solver.cpp:404]     Test net output #1: loss = 0.224615 (* 1 = 0.224615 loss)
I0716 20:26:50.516185  5440 solver.cpp:228] Iteration 980, loss = 0.184994
I0716 20:26:50.516185  5440 solver.cpp:244]     Train net output #0: loss = 0.184994 (* 1 = 0.184994 loss)
I0716 20:26:50.516185  5440 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0716 20:27:13.210729  5440 solver.cpp:337] Iteration 990, Testing net (#0)
I0716 20:28:06.337522  5440 solver.cpp:404]     Test net output #0: accuracy = 0.9178
I0716 20:28:06.337522  5440 solver.cpp:404]     Test net output #1: loss = 0.279823 (* 1 = 0.279823 loss)
I0716 20:28:31.532965  5440 solver.cpp:454] Snapshotting to binary proto file E:/1/TrainModel/Model/_iter_1000.caffemodel
I0716 20:28:31.923918  5440 sgd_solver.cpp:273] Snapshotting solver state to binary proto file E:/1/TrainModel/Model/_iter_1000.solverstate
I0716 20:28:33.189772  5440 solver.cpp:317] Iteration 1000, loss = 0.170574
I0716 20:28:33.189772  5440 solver.cpp:337] Iteration 1000, Testing net (#0)
I0716 20:29:26.641597  5440 solver.cpp:404]     Test net output #0: accuracy = 0.917
I0716 20:29:26.641597  5440 solver.cpp:404]     Test net output #1: loss = 0.299854 (* 1 = 0.299854 loss)
I0716 20:29:26.641597  5440 solver.cpp:322] Optimization Done.
I0716 20:29:26.641597  5440 caffe.cpp:255] Optimization Done.
